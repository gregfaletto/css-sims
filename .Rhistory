1000*.01*.02
14/(.01*.02)
(6*3^3 - 6*1^3)/(3-1)
6*27
(1000*1.05^6 - 1000*1.05^0)/(6- 0)
1000*1.05^6
1000*1.05^0
15.8-14.55
(15.8-14.55)/(2015 - 2011)
(30 + 18)/2
(24 - 6)/(9 - 0)
16*5^2
16*3^2
(16*5^2 - 16*3^2)/(5 - )
(16*5^2 - 16*3^2)/(5 - 3)
400-144
(30300-27000)/(2002-1997)
(31860-30300)/(2004-2002)
(.1 - .4)/(4 - 0)
h <- .1
t <- 3
(4*(t+h)^2 - 4*t^2)/h
h <- .01
(4*(t+h)^2 - 4*t^2)/h
h <- .001
(4*(t+h)^2 - 4*t^2)/h
4*(t+h)^2
4*t^2
h
(4*(t+h)^2 - 4*t^2)/h
4*3.1^2 - 4*3^2
(3^4 - 3^0)/(4 - 0)
3^4 - 3^0
(3^(4+h) - 3^4)/h
h <- .000001
(3^(4+h) - 3^4)/h
(7*(t + h)^2 - 7*t^2)/h
t <- 1
h <- .1
(7*(t + h)^2 - 7*t^2)/h
h <- .01
(7*(t + h)^2 - 7*t^2)/h
h <- .001
(7*(t + h)^2 - 7*t^2)/h
(80.8 - 19.8)/(2010 - 1860)
(80.8 - 75.3)/(2010 - 1990)
(19.8 - 6)/(1860 - 1800)
220*.0218
12.1 - 3*(-.19)
69 + 4*.6
median(c(535, 155, 305, 720, 315, 214))
median(1:11)
median(c(69, 78, 82, 69, 98, 85))
?IQR
IQR(c(5,5,5,6,8,9,11,11,15,16,18,22,25,25,26))
length(c(5,5,5,6,8,9,11,11,15,16,18,22,25,25,26))
IQR(c(1,2,5,7,7,9,15,15,15,22,23,24,26))
length(c(1,2,5,7,7,9,15,15,15,22,23,24,26))
IQR(c(7,5,2,4,3,1,6))
range(c(535, 155, 305, 720, 315, 214))
720-155
85-78
63-48
median(c(90, 94, 84, 87, 89, 85, 83, 79, 72, 70, 72, 68, 69, 65, 53))
IQR(c(90, 94, 84, 87, 89, 85, 83, 79, 72, 70, 72, 68, 69, 65, 53))
50+60+64+50+64
(288-145)*2/3
(288-145)*1/2
MASS::fractions(1 - 2/3 + 1/4)
4282.5 - 573.38 - 1154.72
?as.dist
?cutree
6*16
rm(list=ls())
n <- 100
nsims <- 10
beta_hat_1 <- rep(as.numeric(NA), nsims)
beta_hat_2 <- rep(as.numeric(NA), nsims)
beta_star <- 1
for(i in 1:nsims){
X <- rnorm(n)
T_feat <- rbinom(n)
epsilon <- rnorm(n)
y <- beta_star*X + T_Feat + T_feat*X + epsilon
df <- data.frame(y=y, t=T_feat, x=X)
model1 <- lm(y ~ x, df)
model2 <- lm(y ~ x + t, df)
}
rm(list=ls())
n <- 100
nsims <- 10
beta_hat_1 <- rep(as.numeric(NA), nsims)
beta_hat_2 <- rep(as.numeric(NA), nsims)
beta_star <- 1
for(i in 1:nsims){
X <- rnorm(n)
T_feat <- rbinom(n, size=1)
epsilon <- rnorm(n)
y <- beta_star*X + T_Feat + T_feat*X + epsilon
df <- data.frame(y=y, t=T_feat, x=X)
model1 <- lm(y ~ x, df)
model2 <- lm(y ~ x + t, df)
}
rm(list=ls())
n <- 100
nsims <- 10
beta_hat_1 <- rep(as.numeric(NA), nsims)
beta_hat_2 <- rep(as.numeric(NA), nsims)
beta_star <- 1
for(i in 1:nsims){
X <- rnorm(n)
T_feat <- rbinom(n, size=1, prob=.5)
epsilon <- rnorm(n)
y <- beta_star*X + T_Feat + T_feat*X + epsilon
df <- data.frame(y=y, t=T_feat, x=X)
model1 <- lm(y ~ x, df)
model2 <- lm(y ~ x + t, df)
}
?rbinom
for(i in 1:nsims){
X <- rnorm(n)
T_feat <- rbinom(n, size=1, prob=.5)
epsilon <- rnorm(n)
y <- beta_star*X + T_feat + T_feat*X + epsilon
df <- data.frame(y=y, t=T_feat, x=X)
model1 <- lm(y ~ x, df)
model2 <- lm(y ~ x + t, df)
}
coef(model1)
coelf(model1)$x
coelf(model1)["x"]
coef(model1)["x"]
coef(model2)["x"]
rm(list=ls())
n <- 100
nsims <- 1000
beta_hat_1 <- rep(as.numeric(NA), nsims)
beta_hat_2 <- rep(as.numeric(NA), nsims)
beta_star <- 1
for(i in 1:nsims){
X <- rnorm(n)
T_feat <- rbinom(n, size=1, prob=.5)
epsilon <- rnorm(n)
y <- beta_star*X + T_feat + T_feat*X + epsilon
df <- data.frame(y=y, t=T_feat, x=X)
model1 <- lm(y ~ x, df)
model2 <- lm(y ~ x + t, df)
beta_hat_1[i] <- coef(model1)["x"]
beta_hat_2[i] <- coef(model2)["x"]
}
print("beta_hat_1:")
print(mean(beta_hat_1))
print(sum((beta_hat_1 - beta_star)^2)/nsims)
print("beta_hat_2:")
print(mean(beta_hat_2))
print(sum((beta_hat_2 - beta_star)^2)/nsims)
rm(list=ls())
n <- 100
nsims <- 1000
beta_hat_1 <- rep(as.numeric(NA), nsims)
beta_hat_2 <- rep(as.numeric(NA), nsims)
beta_star <- 1
for(i in 1:nsims){
T_feat <- rbinom(n, size=1, prob=.5)
X <- .5*rnorm(n) + T_feat*.5*rnorm(n)
epsilon <- rnorm(n)
y <- beta_star*X + T_feat + T_feat*X + epsilon
df <- data.frame(y=y, t=T_feat, x=X)
model1 <- lm(y ~ x, df)
model2 <- lm(y ~ x + t, df)
beta_hat_1[i] <- coef(model1)["x"]
beta_hat_2[i] <- coef(model2)["x"]
}
print("beta_hat_1:")
print(mean(beta_hat_1))
print(sum((beta_hat_1 - beta_star)^2)/nsims)
print("beta_hat_2:")
print(mean(beta_hat_2))
print(sum((beta_hat_2 - beta_star)^2)/nsims)
rm(list=ls())
n <- 100
nsims <- 1000
beta_hat_1 <- rep(as.numeric(NA), nsims)
beta_hat_2 <- rep(as.numeric(NA), nsims)
beta_star <- 1
for(i in 1:nsims){
# T_feat <- rbinom(n, size=1, prob=.5)
T_feat <- rnorm(n)
X <- .5*rnorm(n) + .5*T_feat
epsilon <- rnorm(n)
y <- beta_star*X + T_feat + T_feat*X + epsilon
df <- data.frame(y=y, t=T_feat, x=X)
model1 <- lm(y ~ x, df)
model2 <- lm(y ~ x + t, df)
beta_hat_1[i] <- coef(model1)["x"]
beta_hat_2[i] <- coef(model2)["x"]
}
print("beta_hat_1:")
print(mean(beta_hat_1))
print(sum((beta_hat_1 - beta_star)^2)/nsims)
print("beta_hat_2:")
print(mean(beta_hat_2))
print(sum((beta_hat_2 - beta_star)^2)/nsims)
rm(list=ls())
n <- 100
nsims <- 1000
beta_hat_1 <- rep(as.numeric(NA), nsims)
beta_hat_2 <- rep(as.numeric(NA), nsims)
beta_star <- 1
for(i in 1:nsims){
# T_feat <- rbinom(n, size=1, prob=.5)
T_feat <- rnorm(n)
# X <- .5*rnorm(n) + .5*T_feat
X <- rnorm(n)
epsilon <- rnorm(n)
y <- beta_star*X + T_feat + T_feat*X + epsilon
df <- data.frame(y=y, t=T_feat, x=X)
model1 <- lm(y ~ x, df)
model2 <- lm(y ~ x + t, df)
beta_hat_1[i] <- coef(model1)["x"]
beta_hat_2[i] <- coef(model2)["x"]
}
print("beta_hat_1:")
print(mean(beta_hat_1))
print(sum((beta_hat_1 - beta_star)^2)/nsims)
print("beta_hat_2:")
print(mean(beta_hat_2))
print(sum((beta_hat_2 - beta_star)^2)/nsims)
(291.46 + 40.06)/2
1715.22
6946.51-1715.22-1500
1041.69+3731.29
3731.29+1041.69-100
3731.29+1041.69-100-4282.50
?is.data.frame
library(MASS)
fractions(2/18 - 1/256)
fractions(4*(1/3 - 1/5))
fractions(4*(1/4 - 1/6))
fractions(1/3 - (8/15)^2)
package_version("testthat")
library(testthat)
package_version("testthat")
packageVersion("testthat")
remotes::install_github("jacobbien/litr-project", subdir = "litr")
rm(list=ls())
rmarkdown::draft("create-rhello.Rmd", template = "make-an-r-package", package = "litr")
rmarkdown::draft("create-rhello.Rmd", template = "make-an-r-package", package = "litr")
?case_when
library(tidyverse)
p <- c(4/16, 3/16, 2/16, 1/16, 3/16, 2/16, 1/16)
sum(p)
x <- c(0:3, -1:-3)
x
x %*% p
(x - 0)^2 %*% p
sqrt((x - 0)^2 %*% p)
2.5*16
500*1/2400 + 4*4/2400 + 10*10/2400
library(MASS)
fractions(500*1/2400 + 4*4/2400 + 10*10/2400)
77*8
x <- c(500, 4, 10, 0)
p <- c(1/2400, 4/2400, 10/2400, 2385/2400)
sum(p)
(x - 77/300)^2 %*% p
sqrt((x - 77/300)^2 %*% p)
x %*% p
77/300*5
x <- c(-1000, 0, 1000, 2000, 3000)
p <- c(0.13, 0.15, .24, 0.35, 0.13)
x %*% p
sum(p)
(1 - .45)^10
1 - (1 - .45)^10 - 10*.45*(1 - .45)^9
?binomcdf
?rbinom
pbinom(q=5, size=10, prob=0.45)
pbinom(q=0, size=10, prob=0.45)
pbinom(q=1, size=10, prob=0.45)
(1 - .45)^10 + 10*.45*(1 - .45)^9
dbinom(x=3, size=5, prob=0.25)
qnorm(p=0.7, mean=125, sd=6.5)
1 - .7^5 - 5*.3*.7^4
?rgeom
(1 - .19)^4*.19
1/.19
1 - pgeom(10, .19)
4*.6^3*.4 + .6^4
15*.6
sqrt(15*.6*.4)
5400+3070+2200-1720
5400+3070+2200-1720-6033
81346 - 75323
564-69
library(cssr)
data <- genClusteredData(n = 200, # Sample size
p = 100, # Number of features
cluster_size = 10, # Number of features in a cluster correlated with a latent variable
k_unclustered = 10, # Number of unclustered features that influence y
snr = 3 # Signal-to-noise ratio in the response y generated from the data.
)
X <- data$X
y <- data$y
output <- cssSelect(X, y)
rm(list=ls())
data <- genClusteredData(n = 80, # Sample size
p = 40, # Number of features
cluster_size = 10, # Number of features in a cluster correlated with a latent variable
k_unclustered = 10, # Number of unclustered features that influence y
snr = 3 # Signal-to-noise ratio in the response y generated from the data.
)
X <- data$X
y <- data$y
output <- cssSelect(X, y)
output <- cssSelect(X, y)
output$selected_feats
clus_output <- cssSelect(X, y, clusters=list("Z_cluster"=1:10))
clus_output <- cssSelect(X, y, clusters=list("Z_cluster"=1:10))
clus_output$selected_feats
clus_output$selected_clusts
clusters <- list("Z_clust"=1:10, 50:55)
# Wrapper functions (easy!)
n_test <- 50
n <- 200
p <- 100
testx <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
cssPredict(X, y, testx, clusters)
clusters <- list("Z_clust"=1:10, 36:40)
# Wrapper functions (easy!)
n_test <- 50
n <- 80
p <- 40
testx <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
# cssPredict(X, y, testx, clusters)
cssPredict(X, y, testx, clusters)
n_test <- 50
n <- 200
p <- 40
testx <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
cssPredict(X, y, testx, clusters)
inds <- 1:round(n/2)
lambda <- getLassoLambda(X[setdiff(1:n, inds), ], y[setdiff(1:n, inds)])
lambda <- getLassoLambda(X, y)
lambda
results <- css(X=X, y=y, lambda=lambda
, clusters=clusters
# , clusters=list()
# , clusters=1:10
# , sampling.type = "SS"
# B = 100,
# , prop_feats_remove = .5
, train_inds = inds
)
inds <- 1:round(n/2)
results <- css(X=X, y=y, lambda=lambda
, clusters=clusters
# , clusters=list()
# , clusters=1:10
# , sampling.type = "SS"
# B = 100,
# , prop_feats_remove = .5
, train_inds = inds
)
nrow(X)
n
inds <- 1:40
results <- css(X=X, y=y, lambda=lambda
, clusters=clusters
# , clusters=list()
# , clusters=1:10
# , sampling.type = "SS"
# B = 100,
# , prop_feats_remove = .5
, train_inds = inds
)
str(results)
predictions <- results |> getCssPreds(testX = testx, weighting="sparse",
cutoff=0.3
, min_num_clusts=1
, max_num_clusts=3
)
predictions
train_x <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
train_y <- rnorm(n_test)
preds2 <- results |> getCssPreds(testX = testx, weighting=w,
cutoff=c, min_num_clusts=1, max_num_clusts=3,
trainX=train_x
, trainY=train_y
)
preds2 <- results |> getCssPreds(testX = testx, weighting="sparse",
cutoff=0.3, min_num_clusts=1, max_num_clusts=3,
trainX=train_x
, trainY=train_y)
preds2
selections <- results |> getCssSelections(weighting=w, cutoff=c
# , min_num_clusts=1
# , max_num_clusts=3
)
selections <- results |> getCssSelections(weighting="sparse", cutoff=0.3
# , min_num_clusts=1
# , max_num_clusts=3
)
str(selections)
selections$selected_clusts
selections$selected_feats
results |> print.cssr(cutoff=c, min_num_clusts=1, max_num_clusts=3)
print(results)
print(results, cutoff=0.3, max_num_clusts=5)
x_design <- results |> getCssDesign(testx, weighting=w, cutoff=c, min_num_clusts=1, max_num_clusts=3)
x_design <- results |> getCssDesign(testx, weighting="weighted_avg", cutoff=0.3,
min_num_clusts=1, max_num_clusts=3)
str(x_design)
rm(list=ls())
data <- genClusteredData(n = 80, # Sample size
p = 40, # Number of features
cluster_size = 10, # Number of features in a cluster correlated with a latent variable
k_unclustered = 10, # Number of unclustered features that influence y
snr = 3 # Signal-to-noise ratio in the response y generated from the data.
)
X <- data$X
y <- data$y
output <- cssSelect(X, y)
output$selected_feats
library(cssr)
data <- genClusteredData(n = 80, # Sample size
p = 40, # Number of features
cluster_size = 10, # Number of features in a cluster correlated with a latent variable
k_unclustered = 10, # Number of unclustered features that influence y
snr = 3 # Signal-to-noise ratio in the response y generated from the data.
)
X <- data$X
y <- data$y
output <- cssSelect(X, y)
output$selected_feats
clus_output <- cssSelect(X, y, clusters=list("Z_cluster"=1:10))
clus_output$selected_feats
clus_output$selected_clusts
clusters <- list("Z_clust"=1:10, 36:40)
# Wrapper functions (easy!)
n_test <- 50
n <- 80
p <- 40
testx <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
cssPredict(X, y, testx, clusters)
# Get a good lambda
lambda <- getLassoLambda(X, y)
# clusters <- list(1:10, 46:40)
# clusters <- 1:10
inds <- 1:40
results <- css(X=X, y=y, lambda=lambda
, clusters=clusters
# , clusters=list()
# , clusters=1:10
# , sampling.type = "SS"
# B = 100,
# , prop_feats_remove = .5
, train_inds = inds
)
str(results)
predictions <- results |> getCssPreds(testX = testx, weighting="sparse",
cutoff=0.3
, min_num_clusts=1
, max_num_clusts=3
)
predictions
train_x <- matrix(rnorm(n_test*p), nrow=n_test, ncol=p)
train_y <- rnorm(n_test)
preds2 <- results |> getCssPreds(testX = testx, weighting="sparse",
cutoff=0.3, min_num_clusts=1, max_num_clusts=3,
trainX=train_x
, trainY=train_y)
preds2
selections <- results |> getCssSelections(weighting="sparse", cutoff=0.3
# , min_num_clusts=1
# , max_num_clusts=3
)
str(selections)
selections$selected_clusts
selections$selected_feats
print(results, cutoff=0.3, max_num_clusts=5)
x_design <- results |> getCssDesign(testx, weighting="weighted_avg", cutoff=0.3,
min_num_clusts=1, max_num_clusts=3)
str(x_design)
?rowMeans
x_design
rowMeans(x_design)
str(x_design)
str(rowMeans(x_design))
?setdiff
remotes::install_github("jacobbien/litr-project", subdir = "litr",force=TRUE)
4*81
2*3^4
162*2
setwd("~/Documents/GitHub/cssr-project")
devtools::install("cssr/")
setwd("/Users/gregfaletto/Documents/GitHub/css-sims")
source("plant.R")
source("plant.R")
sqrt(45^2/12)
.25*45
.75*25+5
.75*45+3
.75*45+5
5/45 + 10/45
setwd("~/Documents/GitHub/cssr-project")
devtools::install("cssr/")
devtools::test("cssr")
devtools::install("cssr/")
devtools::test("cssr")
setwd("/Users/gregfaletto/Documents/GitHub/css-sims")
source("plant.R")
