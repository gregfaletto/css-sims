# Keep track of minimum eigenvalues
min_eigens <- numeric(2*K)
for(i in 1:(2*K)){
mat_list[[i]] <- matrix(rnorm(p^2), p, p)
min_eigens[i] <- min(eigen(mat_list[[i]])$values)
}
matrix(rnorm(p^2), p, p)
min(eigen(matrix(rnorm(p^2), p, p))$values)
eigen(matrix(rnorm(p^2), p, p)
)
mat_i <- matrix(rnorm(p^2), p, p)
eigen(mat_i)
eigen(mat_i)$values
rm(list=ls())
K <- 10
p <- 20
# Generate 2K random matrices
mat_list <- list()
# Keep track of minimum eigenvalues
min_eigens <- numeric(2*K)
for(i in 1:(2*K)){
mat_i <- matrix(rnorm(p^2), p, p)
mat_list[[i]] <- mat_i
min_eigens[i] <- min(eigen(mat_i)$values)
}
eigen(mat_i)$values
min(eigen(mat_i)$values)
rm(list=ls())
K <- 10
p <- 20
n <- 30
# Generate 2K random PSD matrices
mat_list <- list()
# Keep track of minimum eigenvalues
min_eigens <- numeric(2*K)
for(i in 1:(2*K)){
mat_i <- matrix(rnorm(n*p), n, p)
stopifnot(nrow(t(mat_i) %*% mat_i) == p)
mat_list[[i]] <- t(mat_i) %*% mat_i
min_eigens[i] <- min(eigen(t(mat_i) %*% mat_i)$values)
}
# Label them as X and Y adversarially (min eigenvalues of X are just larger than
# min eigenvalues of Y)
inds <- order(min_eigens, decreasing=TRUE)
# The ones in inds 1, 3,... will be X and inds 2, 4... will be Y
X <- matrix(0, p, p)
Y <- matrix(0, p, p)
for(k in 1:K){
X <- X + mat_list[[2*k - 1]]
Y <- Y + mat_list[[2*k]]
}
# Test
min_eigen_diff <- min(eigen(X - Y)$values)
inds
min_eigens[inds]
# Label them as X and Y adversarially (min eigenvalues of X are just larger than
# min eigenvalues of Y)
inds <- order(min_eigens, decreasing=TRUE)
# The ones in inds 1, 3,... will be X and inds 2, 4... will be Y
X <- matrix(0, p, p)
Y <- matrix(0, p, p)
for(k in 1:K){
X <- X + mat_list[[inds[2*k - 1]]]
Y <- Y + mat_list[[inds2*k]]]
for(k in 1:K){
X <- X + mat_list[[inds[2*k - 1]]]
Y <- Y + mat_list[[inds[2*k]]]
}
# Test
min_eigen_diff <- min(eigen(X - Y)$values)
print("minimum eigenvalue of difference:")
print(min_eigen_diff)
K <- 10
p <- 20
n <- 30
# Generate 2K random PSD matrices
mat_list <- list()
# Keep track of minimum eigenvalues
min_eigens <- numeric(2*K)
for(i in 1:(2*K)){
mat_i <- matrix(rnorm(n*p), n, p)
stopifnot(nrow(t(mat_i) %*% mat_i) == p)
mat_list[[i]] <- t(mat_i) %*% mat_i
min_eigens[i] <- min(eigen(t(mat_i) %*% mat_i)$values)
}
# Label them as X and Y adversarially (min eigenvalues of X are just larger than
# min eigenvalues of Y)
inds <- order(min_eigens, decreasing=TRUE)
# The ones in inds 1, 3,... will be X and inds 2, 4... will be Y
X <- matrix(0, p, p)
Y <- matrix(0, p, p)
for(k in 1:K){
X_k <- mat_list[[inds[2*k - 1]]]
Y_k <- mat_list[[inds[2*k]]]
# double check
stopifnot(min(eigen(X_k)$value) >= min(eigen(Y_k)$value))
X <- X + X_k
Y <- Y + Y_k
}
# Test
min_eigen_diff <- min(eigen(X - Y)$values)
print("minimum eigenvalue of difference:")
print(min_eigen_diff)
K <- 10
p <- 20
n <- 30
# Generate 2K random PSD matrices
mat_list <- list()
rm(list=ls())
K <- 10
p <- 20
n <- 30
# Generate 2K random PSD matrices
mat_list <- list()
# Keep track of minimum eigenvalues
min_eigens <- numeric(2*K)
for(i in 1:(2*K)){
mat_i <- matrix(rnorm(n*p), n, p)
stopifnot(nrow(t(mat_i) %*% mat_i) == p)
mat_list[[i]] <- t(mat_i) %*% mat_i
min_eigens[i] <- min(eigen(t(mat_i) %*% mat_i)$values)
}
X <- matrix(0, p, p)
Y <- matrix(0, p, p)
for(k in 1:K){
X_k <- mat_list[[i]]
# Construct Y_k that is a little bit smaller
Y_k <- X_k - diag(p)*min_eigens[i]/2
# double check
stopifnot(min(eigen(X_k - Y_k)$value) >= 0)
X <- X + X_k
Y <- Y + Y_k
}
# Test
min_eigen_diff <- min(eigen(X - Y)$values)
print("minimum eigenvalue of difference:")
print(min_eigen_diff)
for(j in 1:20){
K <- 10
p <- 20
n <- 30
# Generate 2K random PSD matrices
mat_list <- list()
# Keep track of minimum eigenvalues
min_eigens <- numeric(2*K)
for(i in 1:(2*K)){
mat_i <- matrix(rnorm(n*p), n, p)
stopifnot(nrow(t(mat_i) %*% mat_i) == p)
mat_list[[i]] <- t(mat_i) %*% mat_i
min_eigens[i] <- min(eigen(t(mat_i) %*% mat_i)$values)
}
X <- matrix(0, p, p)
Y <- matrix(0, p, p)
for(k in 1:K){
X_k <- mat_list[[i]]
# Construct Y_k that is a little bit smaller
Y_k <- X_k - diag(p)*min_eigens[i]/2
# double check
stopifnot(min(eigen(X_k - Y_k)$value) >= 0)
X <- X + X_k
Y <- Y + Y_k
}
# Test
min_eigen_diff <- min(eigen(X - Y)$values)
print("minimum eigenvalue of difference:")
print(min_eigen_diff)
}
remotes::install_github("jacobbien/litr-project", subdir = "litr",force=TRUE)
remotes::install_github("gregfaletto/cssr-project", subdir = "cssr")
library(cssr)
?genClusteredData
makeCovarianceMatrixWeighted <- function(p, nblocks, block_size,
n_strong_block_vars, rho_high, rho_low, var) {
# Check inputs
stopifnot(nblocks >= 1)
stopifnot(rho_high != 0)
stopifnot(rho_low != 0)
stopifnot(abs(rho_high) >= abs(rho_low))
stopifnot(var != 0)
stopifnot(abs(rho_high) <= abs(var))
stopifnot(block_size >= 2)
stopifnot(p >= nblocks*block_size)
stopifnot(n_strong_block_vars <= block_size)
# start with p x p identity matrix
Sigma <- var*diag(p)
# create matrix with nblocks rows, each containing a vector of
# indices of highly correlated features
block_feats <- matrix(seq(nblocks*block_size), nrow=nblocks, byrow=TRUE)
stopifnot(length(unique(block_feats)) == length(block_feats))
# add covariances of highly correlated features to sigma
for(i in 1:nblocks){
for(j in 1:(block_size - 1)){
for(k in (j+1):block_size){
feat_1 <- block_feats[i, j]
feat_2 <- block_feats[i, k]
Sigma[feat_1, feat_2] <- rho_low
Sigma[feat_2, feat_1] <- rho_low
}
}
for(j in 1:(n_strong_block_vars - 1)){
for(k in (j+1):n_strong_block_vars){
feat_1 <- block_feats[i, j]
feat_2 <- block_feats[i, k]
Sigma[feat_1, feat_2] <- rho_high
Sigma[feat_2, feat_1] <- rho_high
}
}
}
stopifnot(is.numeric(Sigma))
stopifnot(is.matrix(Sigma))
stopifnot(nrow(Sigma) == p & ncol(Sigma) == p)
stopifnot(all(Sigma == t(Sigma)))
return(Sigma)
}
makeCovarianceMatrixWeighted(p=8, nblocks=1, block_size=5, n_strong_block_vars=2, rho_high=0.9, rho_low=0.5, var=1)
eigen(makeCovarianceMatrixWeighted(p=8, nblocks=1, block_size=5, n_strong_block_vars=2, rho_high=0.9, rho_low=0.5, var=1))$values
setwd("/Users/gregfaletto/Documents/GitHub/css-sims")
# rm(list=ls()[!ls() %in% c("sim_6e")])
# dev.off()
rm(list=ls())
############# Load Libraries #################
library(cssr)
library(simulator) # this file was created under simulator version 0.2.0
library(MASS)
library(glmnet)
library(digest)
library(knitr)
library(ggplot2)
library(doParallel)
library(ccaPP)
library(Metrics)
library(gridExtra)
library(irlba)
library(doMC)
library(parallel)
library(dplyr)
library(cowplot)
# PMA requires library "impute" which is no longer on CRAN. Instructions
# to download as listed on
# http://www.bioconductor.org/packages/release/bioc/html/impute.html:
# ## try http:// if https:// URLs are not supported
# source("https://bioconductor.org/biocLite.R")
# biocLite("impute")
library(PMA)
library(e1071)
############# Load Functions #################
wd <- getwd()
code_dir <- paste(wd, "Helper Functions", sep="/")
# setwd("/Users/gregfaletto/Google Drive/Data Science/R/USC/Stability Selection/toy_example/New method")
# source(file="stabsel_copy.R")
# wd <- "/Users/gregfaletto/Google Drive/Data Science/R/USC/Stability Selection/toy_example"
# setwd(wd)
registerDoParallel()
registerDoMC(cores = detectCores())
setwd(code_dir)
source("toy_ex_slide_funcs.R")
source("model_functions.R")
source("method_functions.R")
source("eval_functions.R")
setwd(wd)
###############################################
# Run simulation, or load simulation that has been previously run?
run_new_sim <- FALSE
# Titles on p_hat plots?
p_hat_titles <- TRUE
# legends on mse/false selection/proxy selection plots
mse_legend <- TRUE
# Only print plot for specific values? (NA if not)
# p_plot <- 100
p_plot <- NA
# beta_plot <- 2
beta_plot <- NA
# Method (choose MB or SS)
method <- "SS"
if(!(method %in% c("SS", "MB"))){
stop("!(method %in% c(SS, MB))")
}
# Seeds (first for model simulations, second for metrics)
seed1 <- 457335
seed2 <- 734355
n_model <- 200
# Number of unlabeled observations used for estimating clusters
n_clus <- 200
# Cutoff for absolute correlation for estimated clusters
est_clus_cutoff <- 0.5
n_test <- 10000
n_sims <- 2000
# n_sims <- 5
# p <- 50
p <- 100
nblocks <- 1
sig_blocks <- 1
k_unblocked <- 10
beta_low <- 1
# beta_high <- 2
beta_high <- 1.5
block_size <- 15
n_strong_block_vars <- 5
rho_high <- 0.9
rho_low <- 0.5
var <- 1
snr <- 3
sigma_eps_sq <- NA
# Number of parameter combinations
n_param_combs <- length(p)*length(n_model)*length(k_unblocked)*length(beta_high)
# Tau for evaluations after simulations
tau <- 0.51
# Maximum number of features to include in stability selection models
p_max <- k_unblocked + sig_blocks
# Methods to evaluate in visualizations
if(method=="SS"){
methods_to_eval <- c(
# "subspace_sel_grass_random",
# "subspace_ss_max_cancor_random",
# "subspace_ss_min_cancor_random",
# "SS_SS_random",
# "SS_SS_random_custom",
# "SS_GSS_random"
"SS_GSS_random_custom"
# , "lasso_random"
# , "SS_GSS_random_avg"
, "SS_GSS_random_avg_custom"
# , "SS_GSS_random_avg_unwt"
, "SS_GSS_random_avg_unwt_custom"
, "BRVZ_avg_unwt"
# , "lasso_proto"
)
}else if(method=="MB"){
methods_to_eval <- c("lasso_random", "lassoMB_phat_random")
}
n_meths_to_eval <- length(methods_to_eval)
# Stability selection-type methods
stab_meths_to_eval <- intersect(methods_to_eval, c("lassoMB_phat_random",
"lassoMB_phat_ideal_random", "lassoMB_phat_cor_squared_random",
"subspace_ss_max_cancor_random", "subspace_sel_grass_random",
"SS_SS_random", "SS_SS_random_custom", "SS_GSS_random",
"SS_GSS_random_custom", "lassoSS_phat_cor_squared_random",
"SS_GSS_random_avg", "SS_GSS_random_avg_custom", "SS_GSS_random_avg_unwt",
"SS_GSS_random_avg_unwt_custom"))
n_stab_meths_to_eval <- length(stab_meths_to_eval)
non_stab_meths <- setdiff(methods_to_eval, stab_meths_to_eval)
# # Display names of possible methods
# DISPLAY_NAMES <- ("Lasso", "Stability Selection", "Sparse CSS",
#     "Weighted Averaged CSS", "Simple Averaged CSS",
#     "Cluster Representative Lasso", "Protolasso")
# if(!("lasso_random" %in% methods_to_eval)){
#     stop("!(lasso_random %in% methods_to_eval)")
# }
known_cluster_meths <- c("SS_CSS_sparse_cssr" # Sparse cluster stability selection
# , SS_GSS_random_custom # Sparse cluster stability selection
, "SS_CSS_weighted_cssr" # Weighted averaged cluster stability
# selection
, "SS_CSS_avg_cssr" # Simple averaged cluster stability
# selection
, "clusRepLasso_cssr" # Cluster representative lasso
, "protolasso_cssr" # Protolasso
)
est_cluster_meths <- c("SS_CSS_sparse_cssr_est" # Sparse cluster stability selection,
# estimated clusters
, "SS_CSS_weighted_cssr_est" # Weighted averaged cluster stability
# selection, estimated clusters
, "SS_CSS_avg_cssr_est" # Simple averaged cluster stability
# selection, estimated clusters
, "clusRepLasso_cssr_est" # Cluster representative lasso, estimated
# clusters
, "protolasso_cssr_est"
)
# Calculate clustered stability metric?
calc_clust_stab <- TRUE
if(calc_clust_stab & (sig_blocks != 1)){
stop("sig_blocks != 1 (can't calculate clustered stability metric)")
}
setwd(wd)
t0 <- Sys.time()
if(run_new_sim){
print("Starting simulations...")
set.seed(seed1)
if(method=="MB"){
gss_random_weighted_custom <- new_simulation("gss_random_weighted_custom",
"GSS (Random Design, Weighted Averaging)") %>%
generate_model(make_model=make_blocked_lin_mod4_ran_weight,
n = n_model,
n_test = n_test,
p = p,
# p = as.list(c(2*n_model, 40*n_model)),
k_unblocked = k_unblocked,
est_clus_cutoff=est_clus_cutoff,
beta_low = beta_low,
beta_high = beta_high,
nblocks = nblocks,
sig_blocks = sig_blocks,
block_size = block_size,
n_strong_block_vars = n_strong_block_vars,
rho_high = rho_high,
rho_low = rho_low,
var = var,
snr = snr
# , vary_along = "p"
) %>% simulate_from_model(nsim = n_sims) %>%
run_method(c(lassoMB_phat_random
, lassoMB_phat_ideal_random
, lassoMB_phat_cor_squared_random
, lasso_random
# , subspace_ss_max_cancor_random
# , list_of_lasso_ps_sss_5_.7_random
# , list_of_lasso_sss_5_.51_random
# , lassoSS_random
)) %>% evaluate(list(phat, labels))
} else{
gss_random_weighted_custom <- new_simulation("gss_random_weighted_custom",
"GSS (Random Design, Weighted Averaging)") %>%
generate_model(make_model=make_blocked_lin_mod4_ran_weight,
n = n_model,
n_clus = n_clus,
n_test = n_test,
p = p,
k_unblocked = k_unblocked,
est_clus_cutoff=est_clus_cutoff,
beta_low = beta_low,
beta_high = beta_high,
nblocks = nblocks,
sig_blocks = sig_blocks,
block_size = block_size,
n_strong_block_vars = n_strong_block_vars,
rho_high = rho_high,
rho_low = rho_low,
var = var,
snr = snr
# , vary_along = ifelse(n_param_combs > 1, "p", NULL)
# , vary_along = c("p", "beta_high")
) %>% simulate_from_model(nsim = n_sims)
gss_random_weighted_custom <- gss_random_weighted_custom %>%
run_method(c(SS_SS_cssr # Stability selection (as proposed by Shah and
# Samworth 2012)
, SS_CSS_sparse_cssr # Sparse cluster stability selection
# , SS_GSS_random_custom # Sparse cluster stability selection
, SS_CSS_weighted_cssr # Weighted averaged cluster stability
# selection
, SS_CSS_avg_cssr # Simple averaged cluster stability
# selection
, clusRepLasso_cssr # Cluster representative lasso
, protolasso_cssr # Protolasso
, lasso_random # Lasso
, elastic_net # Elastic Net
, SS_CSS_sparse_cssr_est # Sparse cluster stability selection,
# estimated clusters
, SS_CSS_weighted_cssr_est # Weighted averaged cluster stability
# selection, estimated clusters
, SS_CSS_avg_cssr_est # Simple averaged cluster stability
# selection, estimated clusters
, clusRepLasso_cssr_est # Cluster representative lasso, estimated
# clusters
, protolasso_cssr_est # Protolasso, estimated clusters
))
gss_random_weighted_custom <- evaluate(gss_random_weighted_custom,
list(cssr_mse))
}
save_simulation(gss_random_weighted_custom)
} else{
print("loading simulation...")
gss_random_weighted_custom <- load_simulation("gss_random_weighted_custom")
print("simulation laoded!")
}
### Generate figures
summary(gss_random_weighted_custom)
gss_random_weighted_custom
str(gss_random_weighted_custom)
1 - pnorm(1.780)
(.05/1.645)^2
.5*.5/.Last.value
.05/1.645
(.05/1.645)^2
23/440
1 - pnorm(23/440, mean=0.03, sd=sqrt(.03*(1-.03)/440))
?pnorm
qnorm(1 - .084/2)
pnorm(1.405)
qnorm(1 - .84/2)
(.02/1.405)^2
qnorm((1-.84)/2)
qnorm(1-(1-.84)/2)
z <- qnorm(1-(1-.84)/2)
(.02/z)^2
.85*(1-.85)/(.02/z)^2
/43 + 1/96*sqrt(.43*(1-.43)/800)
.43 + 1/96*sqrt(.43*(1-.43)/800)
.43 - 1/96*sqrt(.43*(1-.43)/800)
.43*800
.43 - 1.96*sqrt(.43*(1-.43)/800)
.43 + 1.96*sqrt(.43*(1-.43)/800)
.43 + 1.96*sqrt(.5^2)/800)
.43 + 1.96*sqrt(.5^2/800)
.43 - 1.96*sqrt(.5^2/800)
1.96*sqrt(.5^2/800)
1.96*sqrt(.43*(1-.43)/800)
24/40
.6 + 1.96*sqrt(.6*.4/40)
pnorm(.6, .7, sqrt(.6*.4/40))
pnorm(.6, .7, sqrt(.6*.4/40))*2
(.6 -.7)/sqrt(.6*(1-.6)/40)
24/40
34/50
(.68 - .505)/sqrt(.68*(1-.68)/50)
(.68 - .505)/sqrt(.5*(1-.5)/50)
(.68 - .505)/sqrt(.505*(1-.505)/50)
pnorm(.68 - .505)/sqrt(.505*(1-.505)/50))
pnorm((.68 - .505)/sqrt(.505*(1-.505)/50))
1-pnorm((.68 - .505)/sqrt(.505*(1-.505)/50))
(1-pnorm((.68 - .505)/sqrt(.505*(1-.505)/50)))*2
(60 + 23)/60
(60 + 23)/60*90
90*1.5
